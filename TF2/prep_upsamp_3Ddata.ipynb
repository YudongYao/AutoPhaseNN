{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fcf063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first need to download the simulated data\n",
    "# generated by Henry Chan\n",
    "# wget -i aicdi_data.txt\n",
    "# the downloaded data is 32x32x32, this script generates 64x64x64 array by padding the downloaded data and add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "addressed-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from scipy.ndimage.measurements import center_of_mass as com\n",
    "from scipy.ndimage.interpolation import shift\n",
    "from scipy.ndimage.interpolation import rotate as R\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import shutil, tempfile\n",
    "import os\n",
    "\n",
    "import multiprocessing as ms\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "swedish-tours",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54028\n"
     ]
    }
   ],
   "source": [
    "data_folder = './aicdi_data/' #the folder stores the downloaded data\n",
    "\n",
    "dataname = []\n",
    "\n",
    "with open(data_folder+'aicdi_data.txt','r') as f:\n",
    "    txtfile = f.readlines()\n",
    "\n",
    "for i in range(len(txtfile)):\n",
    "    tmp = str(txtfile[i]).split('/')[-1]\n",
    "    dataname.append(tmp.split('\\n')[0])\n",
    "\n",
    "print(len(dataname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "marine-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = './CDI_simulation_upsamp_noise/' #theta\n",
    "\n",
    "if (not os.path.isdir(save_folder)):\n",
    "    os.makedirs(save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "matched-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "M=64\n",
    "def create_obj(filename):\n",
    "    data = np.load(data_folder+filename)\n",
    "    obj = np.fft.ifftn(np.fft.ifftshift(data))\n",
    "    \n",
    "    #Zero everything outside object\n",
    "    obj=np.where(np.abs(obj)<0.1, 0, obj)\n",
    "    \n",
    "    obj_upsamp = np.zeros((M,M,M),dtype = np.complex128)\n",
    "    obj_upsamp[M//2-16:M//2+16,M//2-16:M//2+16,M//2-16:M//2+16] = obj\n",
    "    \n",
    "    diff = np.abs(np.fft.fftshift(np.fft.fftn(obj_upsamp)))\n",
    "    diff=np.random.poisson(lam=diff) #Noise is distribution with sqrt(photons)\n",
    "    \n",
    "    diff = np.float32(diff)\n",
    "    obj_upsamp = np.complex64(obj_upsamp)\n",
    "        \n",
    "    return obj_upsamp,diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pressing-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(filename,save_folder):\n",
    "    if isinstance(filename, list):\n",
    "        if len(filename)>1:\n",
    "            for filename_each in tqdm(filename):\n",
    "                realspace,farfield = create_obj(filename_each)\n",
    "                name = str(filename_each).split('.')[0]\n",
    "                np.savez(save_folder+name+'_0.npz',farfield,realspace)\n",
    "                \n",
    "        else:\n",
    "            realspace,farfield = create_obj(filename[0])\n",
    "            name = str(filename[0]).split('.')[0]\n",
    "            np.savez(save_folder+name+'_0.npz',farfield,realspace)\n",
    "                \n",
    "    else:\n",
    "        realspace,farfield = create_obj(filename)\n",
    "        name = str(filename).split('.')[0]\n",
    "        np.savez(save_folder+name+'_0.npz',farfield,realspace)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hollywood-cameroon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 12 cores\n",
      "4503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4503/4503 [11:18<00:00,  6.63it/s]\n",
      " 93%|█████████▎| 4173/4502 [11:19<01:04,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      ">>>>>                                             processing: [8.3%] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4502/4502 [11:30<00:00,  6.52it/s]\n",
      " 96%|█████████▌| 4316/4502 [11:30<00:27,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      ">>>>>>>>>                                         processing: [16.7%] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4502/4502 [11:48<00:00,  6.35it/s]\n",
      " 97%|█████████▋| 4382/4503 [11:48<00:16,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      ">>>>>>>>>>>>>                                     processing: [25.0%] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4502/4502 [11:58<00:00,  6.27it/s]\n",
      " 99%|█████████▉| 4476/4503 [11:58<00:03,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      ">>>>>>>>>>>>>>>>>                                 processing: [33.3%] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4503/4503 [12:02<00:00,  6.23it/s]\n",
      " 99%|█████████▉| 4479/4503 [12:02<00:03,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      ">>>>>>>>>>>>>>>>>>>>>                             processing: [41.7%] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4502/4502 [12:04<00:00,  6.22it/s]\n",
      "100%|█████████▉| 4492/4503 [12:04<00:01,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>                         processing: [50.0%] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4502/4502 [12:04<00:00,  6.21it/s]\n",
      "100%|█████████▉| 4494/4502 [12:04<00:01,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>                    processing: [58.3%] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4503/4503 [12:05<00:00,  6.20it/s]\n",
      "100%|██████████| 4502/4502 [12:05<00:00,  6.20it/s]\n",
      "100%|█████████▉| 4496/4502 [12:06<00:00,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>                processing: [66.7%] \n",
      "\r\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>            processing: [75.0%] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4502/4502 [12:06<00:00,  6.19it/s]\n",
      "100%|█████████▉| 4497/4503 [12:06<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>        processing: [83.3%] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 4498/4503 [12:07<00:00,  7.52it/s]\n",
      "100%|█████████▉| 4499/4503 [12:07<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>    processing: [91.7%] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4503/4503 [12:07<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>processing: [100.0%] \n"
     ]
    }
   ],
   "source": [
    "n_cores = 12\n",
    "cores = ms.cpu_count()\n",
    "if cores > n_cores:\n",
    "    cores = n_cores\n",
    "else:\n",
    "    cores = ms.cpu_count()\n",
    "print('Use {} cores'.format(cores))\n",
    "\n",
    "keep_dataname = dataname\n",
    "ID_list = np.arange(len(keep_dataname)) #len(keep_dataname)\n",
    "result_list = []\n",
    "\n",
    "index = np.array_split(ID_list, cores)\n",
    "chunks_idx_pattern = [[keep_dataname[int(c)] for c in kk] for kk in index]\n",
    "\n",
    "print(len(chunks_idx_pattern[0]))\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=cores) as executor:\n",
    "\n",
    "    futures = []\n",
    "    for kk, idx_list in enumerate(chunks_idx_pattern):\n",
    "\n",
    "        # start the jobs\n",
    "        futures.append(\n",
    "            executor.submit(data_generator, \n",
    "                            idx_list,save_folder))\n",
    "\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "\n",
    "        try:\n",
    "            result_list.append(future.result())\n",
    "            # display the status of the program\n",
    "            Total_iter = cores\n",
    "            Current_iter = len(result_list)\n",
    "            percent_iter = Current_iter / Total_iter * 100\n",
    "            str_bar = '>' * (int(np.ceil(\n",
    "                percent_iter / 2))) + ' ' * (int(\n",
    "                    (100 - percent_iter) // 2))\n",
    "            print(\n",
    "                '\\r' + str_bar + 'processing: [%3.1f%%] ' %\n",
    "                (percent_iter))\n",
    "\n",
    "        except:\n",
    "            print('Error in the parallel calculation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "grand-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname_list = save_folder+'3D_upsamp.txt'\n",
    "# os.remove(dataname_list)\n",
    "a = open(dataname_list, \"a\")\n",
    "\n",
    "for entry in dataname:\n",
    "    name = str(entry).split('.')[0]\n",
    "    a.write(name + '_0.npz'+ os.linesep)\n",
    "\n",
    "a.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
